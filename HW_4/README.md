# HW_4 Data Analysis Project

## Описание задания

Домашняя работа №4

1. Выберите любой открытый датасет и скачайте открытый датасет, соответствующий вашим интересам или области обучения.
2. Проведите предобработку данных, включая кодирование категориальных признаков и масштабирование числовых признаков.
3. Реализуйте несколько алгоритмов машинного обучения для анализа данных и предсказания целей.
4. Оцените точность моделей и визуализируйте результаты.

## Цель проекта

1. Провести предобработку данных для машинного обучения.
2. Реализовать и обучить несколько моделей машинного обучения.
3. Оценить точность моделей.
4. Визуализировать результаты анализа.

## Структура проекта

Проект состоит из следующих файлов и модулей:

<pre>
HW_4/
├── Data/
│   ├── human-activity-recognition-with-smartphones.zip 
│   ├── train.csv 
│   └── test.csv 
├── Modules/
│   ├── __init__.py
│   ├── data_loader.py
│   ├── eda.py
│   ├── feature_engineering.py
│   ├── model_training.py
│   ├── preprocessing.py
│   └── scaling.py
├── requirements.txt
├── README.md
└── main.ipynb
</pre>

## Файлы с данными

Данные для анализа загружаются по API c сайта kaggle.com:  
https://www.kaggle.com/datasets/uciml/human-activity-recognition-with-smartphones

Архив `human-activity-recognition-with-smartphones.zip` сохраняется в подкаталог `Data`, распаковывается, и модуль считывает две выборки, хранящиеся в CSV-файлах: данные для обучения `train.csv` и для теста `test.csv`.

## Модули и основные функции

### `main.ipynb`

Выполнение анализа данных и визуализация результатов с использованием функций из модулей `data_loader.py`, `eda.py`, `feature_engineering.py`, `model_training.py`, `preprocessing.py` и `scaling.py`.

Содержит следующие этапы:
1. Загрузка данных
2. EDA-анализ
3. Предобработка данных
4. Обучение моделей
5. Сравнение моделей
6. Сравнение лучшей модели на полных данных и после фича-селекции

### `data_loader.py`

- `download_dataset()`: Функция для загрузки датасета с Kaggle.
- `unzip_dataset()`: Функция для распаковки загруженного датасета.
- `load_har_dataset()`: Основная функция для загрузки и распаковки данных.

### `eda.py`

- `load_data()`: Функция для загрузки данных.
- `display_basic_info()`: Функция для отображения основной информации о данных.
- `check_missing_values()`: Функция для проверки пропущенных значений в данных.
- `analyze_target_variable()`: Функция для анализа целевой переменной.
- `detect_outliers()`: Функция для выявления выбросов.
- `analyze_features()`: Функция для анализа признаков и выбора лучших признаков.
- `visualize_features()`: Функция для визуализации признаков.

### `feature_engineering.py`

- `select_k_best_features()`: Функция для выбора k лучших признаков на основе теста ANOVA F.

### `model_training.py`

- `train_logistic_regression()`: Функция для обучения модели логистической регрессии.
- `train_knn()`: Функция для обучения модели K-ближайших соседей.
- `train_svm()`: Функция для обучения модели метода опорных векторов.
- `train_random_forest()`: Функция для обучения модели случайного леса.
- `train_gradient_boosting()`: Функция для обучения модели градиентного бустинга.
- `train_naive_bayes()`: Функция для обучения модели Наивного байесовского классификатора.

### `preprocessing.py`

- `encode_categorical()`: Функция для кодирования категориальных признаков.
- `print_label_mapping()`: Функция для вывода на экран кодировки категориальных признаков.

### `scaling.py`

- `standard_scale()`: Функция для стандартизации числовых признаков.
- `minmax_scale()`: Функция для масштабирования числовых признаков по методу Min-Max.
- `maxabs_scale()`: Функция для масштабирования числовых признаков по методу MaxAbs.
- `normalize()`: Функция для нормализации числовых признаков к единичной длине.

## Запуск проекта

Запустите `main.ipynb` для выполнения анализа данных и визуализации результатов.

